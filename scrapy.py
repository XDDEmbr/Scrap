import random
import requests
import pandas as pd
from time import sleep
import streamlit as st
import plotly.express as px
from utils.scrap import Scarp
from utils.auth import login_warning

html_temp = """
                    <div style="background-color:{};padding:1px">
                    
                    </div>
                    """

def scarp_main():
    
    with st.sidebar:
        st.markdown("""
      # ğŸ”—Tips~
      æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œä»Google Scholarä¸­æå–ç ”ç©¶è®ºæ–‡ç›¸å…³ä¿¡æ¯~
      """)
      
        st.markdown(html_temp.format("rgba(55, 53, 47, 0.16)"),unsafe_allow_html=True)
        st.markdown("""
    # ğŸ”—How does it work?
    åœ¨æ–‡æœ¬å­—æ®µä¸­è¾“å…¥å…³é”®å­—ï¼Œå¹¶é€‰æ‹©ä»Google Scholarç»“æœä¸­æŠ“å–å¤šå°‘é¡µ~  
    """)

    hide="""<style>footer{visibility: hidden;	position: relative;}.viewerBadge_container__1QSob{visibility: hidden;}<style>"""
    st.markdown(hide, unsafe_allow_html=True)
    # æ ‡é¢˜
    st.markdown("""
    ## ğŸ§‘â€ğŸ¨Scholar Scrap
    ä»Google Scholarä¸ŠæŠ“å–ç ”ç©¶è®ºæ–‡ç›¸å…³ä¿¡æ¯~
    """)
    # æŠ“å–åŠŸèƒ½
    # åˆ›å»ºrepository
    paper_repos_dict = {
                        'Paper Title' : [],
                        'Year' : [],
                        'Author' : [],
                        'Citation' : [],
                        'Publication site' : [],
                        'Url of paper' : [] }
    # åœ¨repositoryæ·»åŠ ä¿¡æ¯
    def add_in_paper_repo(papername,year,author,cite,publi,link):
        paper_repos_dict['Paper Title'].extend(papername)
        paper_repos_dict['Year'].extend(year)
        paper_repos_dict['Author'].extend(author)
        paper_repos_dict['Citation'].extend(cite)
        paper_repos_dict['Publication site'].extend(publi)
        paper_repos_dict['Url of paper'].extend(link)
        df = pd.DataFrame(paper_repos_dict)  
        return df

    # headers çˆ¬å–Googleå­¦æœ¯æœç´¢ç»“æœé¡µé¢
    # å®šä¹‰äº†ä¸€ä¸ªHTTPè¯·æ±‚çš„å¤´éƒ¨ä¿¡æ¯å’Œä¸¤ä¸ªå˜é‡ã€‚å¤´éƒ¨ä¿¡æ¯ä¸­åŒ…å«äº†æµè§ˆå™¨ç±»å‹å’Œç‰ˆæœ¬ç­‰ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥å¸®åŠ©æœåŠ¡å™¨äº†è§£å®¢æˆ·ç«¯çš„ç¯å¢ƒã€‚
    # url_beginå’Œurl_endåˆ†åˆ«æ˜¯é“¾æ¥çš„èµ·å§‹éƒ¨åˆ†å’Œç»“æŸéƒ¨åˆ†ï¼Œå…¶ä¸­{}éƒ¨åˆ†å¯ä»¥ç”¨å…·ä½“çš„å‚æ•°æ¥æ›¿æ¢ï¼Œä»è€Œå¾—åˆ°å®Œæ•´çš„é“¾æ¥ã€‚
    # headersï¼šæ˜¯ä¸€ä¸ªå­—å…¸ç±»å‹ï¼ŒåŒ…å«äº†ç”¨æˆ·ä»£ç†ä¿¡æ¯ï¼Œç”¨æ¥æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®ç½‘é¡µï¼Œé¿å…è¢«åçˆ¬è™«æœºåˆ¶ç¦æ­¢è®¿é—®ã€‚

    headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'}
    url_begin = 'https://scholar.google.com/scholar?start={}&q='
    url_end = '&hl=en&as_sdt=0,5='

    # è¾“å…¥
    col1, col2 = st.columns([3,1])
    with col1:
        input_scarp = st.text_input("Search in Google Scholar", key='ScholarScrap',placeholder="What are you looking for?", disabled=False)
    with col2:
        total_to_scrap = st.slider("How many pages to scrap?", min_value=1, max_value=10, step=1, value=2)

    st.markdown(html_temp.format("rgba(55, 53, 47, 0.16)"),unsafe_allow_html=True) #èƒŒæ™¯é¢œè‰²ä¸ºrgba(55, 53, 47, 0.16)



    # åˆ›é€ å­¦è€…url
    if input_scarp:
        text_formated = "+".join(input_scarp.split())
        input_url = url_begin+text_formated+url_end
        if input_url:
            response=requests.get(input_url,headers=headers,timeout=600,verify=False)
            
            total_papers = 10 * total_to_scrap
            for i in range (0,total_papers,10):
                # å¾—åˆ°æ¯ä¸€é¡µçš„url
                url = input_url.format(i)
                # å¾—åˆ°æ¯ä¸€é¡µçš„å†…å®¹
                doc = Scarp.get_paperinfo(url, headers)

                # æ”¶é›†æ ‡ç­¾
                paper_tag,cite_tag,link_tag,author_tag = Scarp.get_tags(doc)

                # æ¯é¡µçš„è®ºæ–‡æ ‡é¢˜
                papername = Scarp.get_papertitle(paper_tag)

                # è®ºæ–‡å‘è¡¨å¹´ä»½ã€å‘è¡¨ç½‘ç«™ã€ä½œè€…
                year , publication , author = Scarp.get_author_year_publi_info(author_tag)

                # è®ºæ–‡å¼•æ•° 
                cite = Scarp.get_citecount(cite_tag)

                # è®ºæ–‡ç½‘å€
                link = Scarp.get_link(link_tag)

                # åŠ å…¥repository
                final = add_in_paper_repo(papername,year,author,cite,publication,link)

                # use sleep to avoid status code 429
                sleep()
        
            final['Year'] = final['Year'].astype('int')
            final['Citation'] = final['Citation'].apply(Scarp.cite_number).astype('int')
            
            # ç”¨expanderç»„ä»¶æ¥åˆ›å»ºä¸€ä¸ªå¯å±•å¼€çš„é¢æ¿ï¼Œå…¶ä¸­åŒ…å«äº†ä¸€ä¸ªæ•°æ®æ¡† finalã€‚
            # åŒæ—¶ï¼Œä»£ç è¿˜é€šè¿‡ convert_df å‡½æ•°å°†æ•°æ®æ¡† final è½¬æ¢æˆäº† CSV æ ¼å¼ï¼Œæœ€åä½¿ç”¨ st.download_button ç»„ä»¶æ·»åŠ ä¸€ä¸ªä¸‹è½½æŒ‰é’®ï¼Œä½¿ç”¨æˆ·å¯ä»¥ä¸‹è½½ CSV æ–‡ä»¶ã€‚ 
            # label å‚æ•°ä¸ºä¸‹è½½æŒ‰é’®çš„æ˜¾ç¤ºæ–‡æœ¬ï¼Œdata å‚æ•°ä¸ºä¸‹è½½çš„æ•°æ®ï¼Œfile_name å‚æ•°æŒ‡å®šè¦ä¸‹è½½çš„æ–‡ä»¶åï¼Œmime å‚æ•°ä¸ºæ–‡ä»¶ç±»å‹ã€‚
            with st.expander("Extracted papers"):
                st.dataframe(final)
                csv = Scarp.convert_df(final)
                file_name_value = "_".join(input_scarp.split())+'.csv'
            st.download_button(
                label="Download data as CSV",
                data=csv,
                file_name=file_name_value,
                mime='text/csv',
            )

            # ç»˜åˆ¶ï¼Œä¸¤åˆ—çš„æ ¼å¼
            col1, col2 = st.columns([2,1])

            # æ˜¾ç¤ºè®ºæ–‡å‘è¡¨å¹´ä»½å’Œå¼•ç”¨çš„åˆ†å¸ƒæƒ…å†µï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä½¿ç”¨å¼•ç”¨ä½œä¸ºæ°”æ³¡å¤§å°
            with col1:
                with st.expander("Distribution of papers by year and citation", expanded=True):
                    size_button = st.checkbox('Set Citation as bubble size', value=True)
                    size_value = None
                    if size_button:
                        size_value = 'Citation'
                    final_sorted = final.sort_values(by='Year', ascending=True)
                    fig1 = px.scatter(
                          final_sorted, 
                          x="Year", 
                          color="Publication site",
                          size=size_value, 
                          log_x=True, 
                          size_max=60
                          )
                    fig1.update_xaxes(type='category')
                    st.plotly_chart(fig1, theme="streamlit", use_container_width=True)

            # æ˜¾ç¤ºå‡ºç‰ˆç‰©ç½‘ç«™çš„ç™¾åˆ†æ¯”
            with col2:
                percentage_sites = {}
                sites = list(final_sorted['Publication site'])
                for i in sites:
                    percentage_sites[i] = sites.count(i)/len(sites)*100
                df_per = pd.DataFrame(list(zip(percentage_sites.keys(), percentage_sites.values())), columns=['sites', 'percentage'])
          
                fig2 = px.pie(
                      df_per, 
                      values="percentage", 
                      names="sites", 
                      )
                with st.expander("å‘è¡¨ç½‘ç«™çš„ç™¾åˆ†æ¯”", expanded=True):
                    st.plotly_chart(fig2, theme="streamlit", use_container_width=True)

            with st.expander("ä½œè€…å‘è¡¨æ–‡çŒ®çš„ç™¾åˆ†æ¯”", expanded=True): 
                # å°†æ¯ç¯‡æ–‡ç« çš„ä½œè€…åˆ—è¡¨æŒ‰ç…§é€—å·åˆ†éš”å¹¶ä¸”å»é™¤ç©ºæ ¼ï¼Œå¹¶ç”Ÿæˆæ–°çš„DataFrame
                author_list = final_sorted['Author'].str.split(",|ï¼Œ", expand=True).apply(lambda x: x.str.strip())
      
                # å¯¹æ–°çš„DataFrameä½¿ç”¨groupbyå‡½æ•°æŒ‰ç…§ä½œè€…è¿›è¡Œåˆ†ç»„ï¼Œå¹¶ä½¿ç”¨value_countså‡½æ•°è®¡ç®—æ¯ä¸ªä½œè€…çš„æ–‡ç« æ•°é‡
                author_counts = author_list.stack().value_counts()
      
                # å°†ç»Ÿè®¡ç»“æœç”Ÿæˆæ–°çš„DataFrameï¼Œå¹¶å°†ä½œè€…å’Œå¯¹åº”çš„æ–‡ç« æ•°é‡ä½œä¸ºåˆ—å
                df_au_per = pd.DataFrame({"authors": author_counts.index, "article_count": author_counts.values})
      
                # ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼Œä»¥ä½œè€…ä½œä¸ºåˆ†ç±»ï¼Œæ–‡ç« æ•°é‡ä½œä¸ºå€¼
                colors = ['#'+"".join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(df_au_per))]
                fig = px.bar(df_au_per, x='authors', y='article_count', color=colors)
                fig.update_traces(texttemplate='%{y}', textposition='outside', textfont_size=12)
                fig.update_layout(xaxis_tickangle=45)
                st.plotly_chart(fig, theme="streamlit", use_container_width=True)

if __name__ == '__main__':
    if st.session_state.authentication_status:
        scarp_main()
    elif st.session_state.authentication_status == None:
        login_warning()       
